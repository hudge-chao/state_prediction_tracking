{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if '/opt/ros/kinetic/lib/python2.7/dist-packages' in sys.path:\n",
    "    sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch \n",
    "from ConvAE import Encoder, Decoder\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import tensorboardX\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAE_Dataset(Dataset):\n",
    "    def __init__(self, dir=\"./maps\") -> None:\n",
    "        super().__init__()\n",
    "        self.dataset_dir = dir\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        files = os.listdir(self.dataset_dir)\n",
    "        return len(files)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_name = \"{}.png\".format(index)\n",
    "        image_path = os.path.join(self.dataset_dir, image_name)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = image / 255.0\n",
    "        image = np.expand_dims(image, 0)\n",
    "        return image, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataset = ConvAE_Dataset(\"./localmaps\")\n",
    "\n",
    "train_dataset_size = int(len(myDataset) * 0.8)\n",
    "test_dataset_size = len(myDataset) - train_dataset_size\n",
    "# validate_dataset_size = len(myDataset) - (train_dataset_size + test_dataset_size)\n",
    "\n",
    "# train_dataset, test_dataset, validate_dataset = random_split(myDataset, [train_dataset_size, test_dataset_size, validate_dataset_size])\n",
    "train_dataset, test_dataset = random_split(myDataset, [train_dataset_size, test_dataset_size])\n",
    "\n",
    "# train_dataset_loader = DataLoader(train_dataset, batch_size=20, shuffle=False) \n",
    "\n",
    "train_dataset_loader = DataLoader(train_dataset, batch_size=20, shuffle=False) \n",
    "test_dataset_loader = DataLoader(test_dataset, batch_size=20, shuffle=False) \n",
    "# validate_dataset_loader = DataLoader(validate_dataset, batch_size=20, shuffle=False) \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "print('数据集样本数量: ', len(myDataset))\n",
    "\n",
    "print('图片尺寸: ', myDataset[0][0].shape)\n",
    "\n",
    "writer = tensorboardX.SummaryWriter('./log', flush_secs=2)\n",
    "\n",
    "train_epoches = 500\n",
    "\n",
    "evaluate_frequency = 10\n",
    "\n",
    "test_frequency = 5\n",
    "\n",
    "save_weight_frequency = 50\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.Softmax2d()\n",
    "\n",
    "lr = 0.005\n",
    " \n",
    "encoder = Encoder()\n",
    "decoder = Decoder()\n",
    "\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-5)\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(train_epoches):\n",
    "    train_loss_epoch = []\n",
    "    for image_batch, index_batch in train_dataset_loader:\n",
    "        image_batch_tensor = image_batch.clone().detach().float().to(device)\n",
    "        encoded_data = encoder(image_batch_tensor)\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        loss = torch.sqrt((decoded_data - image_batch_tensor).pow(2).mean())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_numpy = loss.detach().cpu().numpy()\n",
    "        train_loss_epoch.append(loss_numpy)\n",
    "    train_loss_avg = np.mean(train_loss_epoch)\n",
    "    writer.add_scalar('train loss', train_loss_avg * 1000, global_step=i+1)\n",
    "    print(\"train epoch: {}, train loss: {}\".format(i+1, train_loss_avg * 1000))\n",
    "\n",
    "    if (i % evaluate_frequency == 0 and i != 0):\n",
    "        test_loss_epoch = []\n",
    "        for image_test_batch, index_test_batch in test_dataset_loader:\n",
    "            image_test_batch_tensor = image_test_batch.clone().detach().float().to(device)\n",
    "            encoded_test_data = encoder(image_test_batch_tensor)\n",
    "            decoded_test_data = decoder(encoded_test_data)\n",
    "            loss = torch.sqrt((decoded_test_data - image_test_batch_tensor).pow(2).mean())\n",
    "            loss_numpy = loss.detach().cpu().numpy()\n",
    "            test_loss_epoch.append(loss_numpy)\n",
    "        test_loss_avg = np.mean(test_loss_epoch)\n",
    "        writer.add_scalar('test loss', test_loss_avg * 1000, global_step=(i / evaluate_frequency))\n",
    "        print(\"test epoch: {}, test loss: {}\".format(i / evaluate_frequency, test_loss_avg * 1000))\n",
    "\n",
    "    if (i % test_frequency == 0 and i != 0):\n",
    "        print('------test------')\n",
    "        selected_sample_index = random.randint(0, len(myDataset))\n",
    "        selected_sample = myDataset[selected_sample_index][0]\n",
    "        selected_image_origin = np.expand_dims(selected_sample, 0)\n",
    "        # print(selected_image_origin.shape)\n",
    "        selected_image_origin = torch.tensor(selected_image_origin, dtype=torch.float)\n",
    "        selected_image_origin_tensor = selected_image_origin.clone().detach().to(device)\n",
    "        selected_image_infer_tensor = decoder(encoder(selected_image_origin_tensor))\n",
    "        selected_image_infer = selected_image_infer_tensor.detach().cpu().numpy()[0]\n",
    "        selected_image_origin_show =  selected_sample[0] * 255.0\n",
    "        selected_image_infer_show = selected_image_infer[0] * 255.0\n",
    "        image_concat = np.hstack((selected_image_origin_show, selected_image_infer_show))\n",
    "        cv2.imwrite(\"result.png\", image_concat)\n",
    "\n",
    "    if (i % save_weight_frequency == 0 and i != 0):\n",
    "        print('======= saving models =======')\n",
    "        torch.save(encoder.state_dict(), \"./weights/{}_encoder.pth\".format(i))\n",
    "        torch.save(decoder.state_dict(), \"./weights/{}_decoder.pth\".format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ab5697f9e69cd78b920c03fde1b23dee35d76387e0a20d35fdb77766e38d53b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
